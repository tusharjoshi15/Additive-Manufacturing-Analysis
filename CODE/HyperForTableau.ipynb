{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd5452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kernel is working!\n",
      "Python Path: /opt/homebrew/opt/python@3.11/bin/python3.11\n",
      "Polars version: 1.31.0\n",
      "CPU count: 10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import polars as pl\n",
    "import psutil\n",
    "\n",
    "print(\"✅ Kernel is working!\")\n",
    "print(\"Python Path:\", sys.executable)\n",
    "print(\"Polars version:\", pl.__version__)\n",
    "print(\"CPU count:\", psutil.cpu_count(logical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb71869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD of First Batch:\n",
      "shape: (5, 15)\n",
      "┌─────────┬─────────────────┬─────────────────┬──────────┬───┬──────┬───────┬───────────┬──────────┐\n",
      "│ check   ┆ date            ┆ id              ┆ state    ┆ … ┆ flow ┆ speed ┆ fanHotend ┆ fanPrint │\n",
      "│ ---     ┆ ---             ┆ ---             ┆ ---      ┆   ┆ ---  ┆ ---   ┆ ---       ┆ ---      │\n",
      "│ str     ┆ str             ┆ str             ┆ str      ┆   ┆ i64  ┆ i64   ┆ i64       ┆ i64      │\n",
      "╞═════════╪═════════════════╪═════════════════╪══════════╪═══╪══════╪═══════╪═══════════╪══════════╡\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1522X017XC7 ┆ FINISHED ┆ … ┆ 30   ┆ 100   ┆ 0         ┆ 0        │\n",
      "│         ┆ 7:00.652Z       ┆ 8087            ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX4521X017XC6 ┆ IDLE     ┆ … ┆ 100  ┆ 100   ┆ 0         ┆ 0        │\n",
      "│         ┆ 7:00.757Z       ┆ 4043            ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1622X017XC7 ┆ IDLE     ┆ … ┆ 100  ┆ 100   ┆ 0         ┆ 0        │\n",
      "│         ┆ 7:00.827Z       ┆ 8384            ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1522X017XC7 ┆ IDLE     ┆ … ┆ 30   ┆ 100   ┆ 0         ┆ 0        │\n",
      "│         ┆ 7:00.896Z       ┆ 8307            ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX4921X017XC6 ┆ IDLE     ┆ … ┆ 30   ┆ 100   ┆ 0         ┆ 0        │\n",
      "│         ┆ 7:00.974Z       ┆ 7390            ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "└─────────┴─────────────────┴─────────────────┴──────────┴───┴──────┴───────┴───────────┴──────────┘\n",
      "\n",
      "TAIL of Last Batch:\n",
      "shape: (5, 15)\n",
      "┌─────────────────┬─────────────────┬─────────┬──────────┬───┬──────┬───────┬───────────┬──────────┐\n",
      "│ date            ┆ id              ┆ check   ┆ state    ┆ … ┆ flow ┆ speed ┆ fanHotend ┆ fanPrint │\n",
      "│ ---             ┆ ---             ┆ ---     ┆ ---      ┆   ┆ ---  ┆ ---   ┆ ---       ┆ ---      │\n",
      "│ str             ┆ str             ┆ str     ┆ str      ┆   ┆ i64  ┆ i64   ┆ i64       ┆ i64      │\n",
      "╞═════════════════╪═════════════════╪═════════╪══════════╪═══╪══════╪═══════╪═══════════╪══════════╡\n",
      "│ 2025-04-29T22:5 ┆ CZPX4921X017XC6 ┆ success ┆ IDLE     ┆ … ┆ 100  ┆ 100   ┆ 0         ┆ 0        │\n",
      "│ 9:59.165Z       ┆ 7390            ┆         ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1522X017XC7 ┆ success ┆ FINISHED ┆ … ┆ 100  ┆ 100   ┆ 0         ┆ 0        │\n",
      "│ 9:59.166Z       ┆ 8087            ┆         ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1622X017XC7 ┆ failed  ┆ null     ┆ … ┆ null ┆ null  ┆ null      ┆ null     │\n",
      "│ 9:59.797Z       ┆ 8491            ┆         ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1622X017XC7 ┆ failed  ┆ null     ┆ … ┆ null ┆ null  ┆ null      ┆ null     │\n",
      "│ 9:59.798Z       ┆ 8491            ┆         ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "│ 2025-04-29T23:0 ┆ CZPX1622X017XC7 ┆ failed  ┆ null     ┆ … ┆ null ┆ null  ┆ null      ┆ null     │\n",
      "│ 0:01.363Z       ┆ 8456            ┆         ┆          ┆   ┆      ┆       ┆           ┆          │\n",
      "└─────────────────┴─────────────────┴─────────┴──────────┴───┴──────┴───────┴───────────┴──────────┘\n",
      "\n",
      "Schema of First Batch:\n",
      "Schema([('check', String), ('date', String), ('id', String), ('state', String), ('tempBed', Float64), ('targetBed', Int64), ('tempNozzle', Float64), ('targetNozzle', Int64), ('axisZ', Float64), ('axisX', Float64), ('axisY', Int64), ('flow', Int64), ('speed', Int64), ('fanHotend', Int64), ('fanPrint', Int64)])\n",
      "\n",
      "Schema of Last Batch:\n",
      "Schema([('date', String), ('id', String), ('check', String), ('state', String), ('tempBed', Float64), ('targetBed', Int64), ('tempNozzle', Float64), ('targetNozzle', Int64), ('axisZ', Float64), ('axisX', Int64), ('axisY', Int64), ('flow', Int64), ('speed', Int64), ('fanHotend', Int64), ('fanPrint', Int64)])\n"
     ]
    }
   ],
   "source": [
    "# import polars as pl\n",
    "\n",
    "# # Read head from first file\n",
    "# first_file = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed/batch_001.parquet\"\n",
    "# df_first = pl.read_parquet(first_file)\n",
    "# print(\"HEAD of First Batch:\")\n",
    "# print(df_first.head(5))\n",
    "\n",
    "# # Read tail from last file\n",
    "# last_file = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed/batch_034.parquet\"\n",
    "# df_last = pl.read_parquet(last_file)\n",
    "# print(\"\\nTAIL of Last Batch:\")\n",
    "# print(df_last.tail(5))\n",
    "\n",
    "# print(\"\\nSchema of First Batch:\")\n",
    "# print(df_first.schema)\n",
    "\n",
    "# print(\"\\nSchema of Last Batch:\")\n",
    "# print(df_last.schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9dcce",
   "metadata": {},
   "source": [
    "we have to handle the mismatch of data types and impose float64 for all the sensor fields and rexport parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da623f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Re-exported all batches with float sensor fields.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import glob\n",
    "\n",
    "input_dir = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed\"\n",
    "output_dir = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define sensor fields to cast\n",
    "sensor_fields = [\n",
    "    \"tempBed\", \"targetBed\", \"tempNozzle\", \"targetNozzle\",\n",
    "    \"axisZ\", \"axisX\", \"axisY\", \"flow\", \"speed\", \"fanHotend\", \"fanPrint\"\n",
    "]\n",
    "\n",
    "parquet_files = glob.glob(os.path.join(input_dir, \"*.parquet\"))\n",
    "\n",
    "for file in parquet_files:\n",
    "    df = pl.read_parquet(file)\n",
    "\n",
    "    # Force cast sensor fields to Float64\n",
    "    for field in sensor_fields:\n",
    "        if field in df.columns:\n",
    "            df = df.with_columns(pl.col(field).cast(pl.Float64))\n",
    "\n",
    "    # Save to new file\n",
    "    out_path = os.path.join(output_dir, os.path.basename(file))\n",
    "    df.write_parquet(out_path)\n",
    "\n",
    "print(\"✅ Re-exported all batches with float sensor fields.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16fbbb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD of First Batch:\n",
      "shape: (5, 15)\n",
      "┌─────────┬─────────────────┬────────────────┬──────────┬───┬───────┬───────┬───────────┬──────────┐\n",
      "│ check   ┆ date            ┆ id             ┆ state    ┆ … ┆ flow  ┆ speed ┆ fanHotend ┆ fanPrint │\n",
      "│ ---     ┆ ---             ┆ ---            ┆ ---      ┆   ┆ ---   ┆ ---   ┆ ---       ┆ ---      │\n",
      "│ str     ┆ str             ┆ str            ┆ str      ┆   ┆ f64   ┆ f64   ┆ f64       ┆ f64      │\n",
      "╞═════════╪═════════════════╪════════════════╪══════════╪═══╪═══════╪═══════╪═══════════╪══════════╡\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1522X017XC ┆ FINISHED ┆ … ┆ 30.0  ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│         ┆ 7:00.652Z       ┆ 78087          ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX4521X017XC ┆ IDLE     ┆ … ┆ 100.0 ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│         ┆ 7:00.757Z       ┆ 64043          ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1622X017XC ┆ IDLE     ┆ … ┆ 100.0 ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│         ┆ 7:00.827Z       ┆ 78384          ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX1522X017XC ┆ IDLE     ┆ … ┆ 30.0  ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│         ┆ 7:00.896Z       ┆ 78307          ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ success ┆ 2024-04-03T12:2 ┆ CZPX4921X017XC ┆ IDLE     ┆ … ┆ 30.0  ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│         ┆ 7:00.974Z       ┆ 67390          ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "└─────────┴─────────────────┴────────────────┴──────────┴───┴───────┴───────┴───────────┴──────────┘\n",
      "\n",
      "TAIL of Last Batch:\n",
      "shape: (5, 15)\n",
      "┌─────────────────┬────────────────┬─────────┬──────────┬───┬───────┬───────┬───────────┬──────────┐\n",
      "│ date            ┆ id             ┆ check   ┆ state    ┆ … ┆ flow  ┆ speed ┆ fanHotend ┆ fanPrint │\n",
      "│ ---             ┆ ---            ┆ ---     ┆ ---      ┆   ┆ ---   ┆ ---   ┆ ---       ┆ ---      │\n",
      "│ str             ┆ str            ┆ str     ┆ str      ┆   ┆ f64   ┆ f64   ┆ f64       ┆ f64      │\n",
      "╞═════════════════╪════════════════╪═════════╪══════════╪═══╪═══════╪═══════╪═══════════╪══════════╡\n",
      "│ 2025-04-29T22:5 ┆ CZPX4921X017XC ┆ success ┆ IDLE     ┆ … ┆ 100.0 ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│ 9:59.165Z       ┆ 67390          ┆         ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1522X017XC ┆ success ┆ FINISHED ┆ … ┆ 100.0 ┆ 100.0 ┆ 0.0       ┆ 0.0      │\n",
      "│ 9:59.166Z       ┆ 78087          ┆         ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1622X017XC ┆ failed  ┆ null     ┆ … ┆ null  ┆ null  ┆ null      ┆ null     │\n",
      "│ 9:59.797Z       ┆ 78491          ┆         ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ 2025-04-29T22:5 ┆ CZPX1622X017XC ┆ failed  ┆ null     ┆ … ┆ null  ┆ null  ┆ null      ┆ null     │\n",
      "│ 9:59.798Z       ┆ 78491          ┆         ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "│ 2025-04-29T23:0 ┆ CZPX1622X017XC ┆ failed  ┆ null     ┆ … ┆ null  ┆ null  ┆ null      ┆ null     │\n",
      "│ 0:01.363Z       ┆ 78456          ┆         ┆          ┆   ┆       ┆       ┆           ┆          │\n",
      "└─────────────────┴────────────────┴─────────┴──────────┴───┴───────┴───────┴───────────┴──────────┘\n",
      "\n",
      "Schema of First Batch:\n",
      "Schema([('check', String), ('date', String), ('id', String), ('state', String), ('tempBed', Float64), ('targetBed', Float64), ('tempNozzle', Float64), ('targetNozzle', Float64), ('axisZ', Float64), ('axisX', Float64), ('axisY', Float64), ('flow', Float64), ('speed', Float64), ('fanHotend', Float64), ('fanPrint', Float64)])\n",
      "\n",
      "Schema of Last Batch:\n",
      "Schema([('date', String), ('id', String), ('check', String), ('state', String), ('tempBed', Float64), ('targetBed', Float64), ('tempNozzle', Float64), ('targetNozzle', Float64), ('axisZ', Float64), ('axisX', Float64), ('axisY', Float64), ('flow', Float64), ('speed', Float64), ('fanHotend', Float64), ('fanPrint', Float64)])\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read head from first file\n",
    "first_file = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float/batch_001.parquet\"\n",
    "df_first = pl.read_parquet(first_file)\n",
    "print(\"HEAD of First Batch:\")\n",
    "print(df_first.head(5))\n",
    "\n",
    "# Read tail from last file\n",
    "last_file = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float/batch_034.parquet\"\n",
    "df_last = pl.read_parquet(last_file)\n",
    "print(\"\\nTAIL of Last Batch:\")\n",
    "print(df_last.tail(5))\n",
    "\n",
    "print(\"\\nSchema of First Batch:\")\n",
    "print(df_first.schema)\n",
    "\n",
    "print(\"\\nSchema of Last Batch:\")\n",
    "print(df_last.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78aed769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 parquet files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from tableauhyperapi import HyperProcess, Connection, Telemetry, TableDefinition, SqlType, Inserter, CreateMode, TableName\n",
    "\n",
    "# Set your input and output paths\n",
    "parquet_folder = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float\"\n",
    "output_hyper_file = \"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /printer_data.hyper\"\n",
    "\n",
    "#  List all parquet files in the folder\n",
    "all_parquet_files = sorted([\n",
    "    os.path.join(parquet_folder, f)\n",
    "    for f in os.listdir(parquet_folder)\n",
    "    if f.endswith(\".parquet\")\n",
    "])\n",
    "\n",
    "print(f\"Found {len(all_parquet_files)} parquet files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c1c1d",
   "metadata": {},
   "source": [
    "defining the schema for the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48fec97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDefinition(TableName('Extract', 'PrinterData'), [Column('check', SqlType.text(), Nullability.NULLABLE), Column('date', SqlType.text(), Nullability.NULLABLE), Column('id', SqlType.text(), Nullability.NULLABLE), Column('state', SqlType.text(), Nullability.NULLABLE), Column('tempBed', SqlType.double(), Nullability.NULLABLE), Column('targetBed', SqlType.double(), Nullability.NULLABLE), Column('tempNozzle', SqlType.double(), Nullability.NULLABLE), Column('targetNozzle', SqlType.double(), Nullability.NULLABLE), Column('axisZ', SqlType.double(), Nullability.NULLABLE), Column('axisX', SqlType.double(), Nullability.NULLABLE), Column('axisY', SqlType.double(), Nullability.NULLABLE), Column('flow', SqlType.double(), Nullability.NULLABLE), Column('speed', SqlType.double(), Nullability.NULLABLE), Column('fanHotend', SqlType.double(), Nullability.NULLABLE), Column('fanPrint', SqlType.double(), Nullability.NULLABLE)], Persistence.PERMANENT)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the schema and table name\n",
    "table_name = TableName(\"Extract\", \"PrinterData\")\n",
    "\n",
    "# Create the table definition and add columns explicitly\n",
    "printer_table = TableDefinition(table_name)\n",
    "printer_table.add_column(\"check\", SqlType.text())\n",
    "printer_table.add_column(\"date\", SqlType.text())\n",
    "printer_table.add_column(\"id\", SqlType.text())\n",
    "printer_table.add_column(\"state\", SqlType.text())\n",
    "printer_table.add_column(\"tempBed\", SqlType.double())\n",
    "printer_table.add_column(\"targetBed\", SqlType.double())\n",
    "printer_table.add_column(\"tempNozzle\", SqlType.double())\n",
    "printer_table.add_column(\"targetNozzle\", SqlType.double())\n",
    "printer_table.add_column(\"axisZ\", SqlType.double())\n",
    "printer_table.add_column(\"axisX\", SqlType.double())\n",
    "printer_table.add_column(\"axisY\", SqlType.double())\n",
    "printer_table.add_column(\"flow\", SqlType.double())\n",
    "printer_table.add_column(\"speed\", SqlType.double())\n",
    "printer_table.add_column(\"fanHotend\", SqlType.double())\n",
    "printer_table.add_column(\"fanPrint\", SqlType.double())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87a0ab",
   "metadata": {},
   "source": [
    "since the schema is defined now we move on to creating the .hyper file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40af3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start the Hyper process and create a new .hyper file\n",
    "# hyper = HyperProcess(telemetry=Telemetry.DO_NOT_SEND)\n",
    "\n",
    "# connection = Connection(\n",
    "#     endpoint=hyper.endpoint,\n",
    "#     database=output_hyper_file,\n",
    "#     create_mode=CreateMode.CREATE_AND_REPLACE\n",
    "# )\n",
    "\n",
    "# # Create the table schema inside the .hyper file\n",
    "# connection.catalog.create_schema(\"Extract\")\n",
    "# connection.catalog.create_table(printer_table)\n",
    "\n",
    "# print(\"Hyper file and table created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6c8d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.22502\n"
     ]
    }
   ],
   "source": [
    "import tableauhyperapi\n",
    "print(tableauhyperapi.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb6e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Hyper process and create a new .hyper file\n",
    "from tableauhyperapi import HyperProcess, Connection, CreateMode\n",
    "\n",
    "with HyperProcess(telemetry=\"DO_NOT_SEND_USAGE_DATA_TO_TABLEAU\") as hyper:\n",
    "    with Connection(endpoint=hyper.endpoint, database=output_hyper_file, create_mode=CreateMode.CREATE_AND_REPLACE) as connection:\n",
    "        connection.catalog.create_schema(\"Extract\")\n",
    "        connection.catalog.create_table(printer_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0abff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting batch 1/34: batch_001.parquet\n",
      "rows: 3331416, Min Date: 2024-04-03T12:27:00.652Z, Max Date: 2024-04-18T23:00:00.065Z\n",
      "Inserting batch 2/34: batch_002.parquet\n",
      "rows: 2805908, Min Date: 2024-04-23T06:44:02.861Z, Max Date: 2024-05-02T22:59:59.551Z\n",
      "Inserting batch 3/34: batch_003.parquet\n",
      "rows: 3005163, Min Date: 2024-05-02T23:00:01.555Z, Max Date: 2024-05-12T23:00:00.995Z\n",
      "Inserting batch 4/34: batch_004.parquet\n",
      "rows: 3005002, Min Date: 2024-05-12T23:00:01.927Z, Max Date: 2024-05-22T22:59:59.714Z\n",
      "Inserting batch 5/34: batch_005.parquet\n",
      "rows: 2223424, Min Date: 2024-05-22T23:00:00.693Z, Max Date: 2024-06-04T07:54:27.723Z\n",
      "Inserting batch 6/34: batch_006.parquet\n",
      "rows: 2292976, Min Date: 2024-06-02T01:39:52.016Z, Max Date: 2024-06-11T23:00:01.412Z\n",
      "Inserting batch 7/34: batch_007.parquet\n",
      "rows: 3004799, Min Date: 2024-06-11T23:00:00.363Z, Max Date: 2024-06-21T22:59:59.535Z\n",
      "Inserting batch 8/34: batch_008.parquet\n",
      "rows: 3004960, Min Date: 2024-06-21T23:00:01.549Z, Max Date: 2024-07-01T22:59:58.598Z\n",
      "Inserting batch 9/34: batch_009.parquet\n",
      "rows: 3005002, Min Date: 2024-07-01T23:00:00.623Z, Max Date: 2024-07-11T23:00:00.199Z\n",
      "Inserting batch 10/34: batch_010.parquet\n",
      "rows: 3005135, Min Date: 2024-07-11T23:00:01.242Z, Max Date: 2024-07-21T22:59:59.530Z\n",
      "Inserting batch 11/34: batch_011.parquet\n",
      "rows: 2150302, Min Date: 2024-07-21T23:00:01.572Z, Max Date: 2024-08-05T09:27:26.616Z\n",
      "Inserting batch 12/34: batch_012.parquet\n",
      "rows: 2230298, Min Date: 2024-08-03T00:06:36.825Z, Max Date: 2024-08-12T22:59:59.147Z\n",
      "Inserting batch 13/34: batch_013.parquet\n",
      "rows: 3004981, Min Date: 2024-08-12T23:00:01.182Z, Max Date: 2024-08-22T22:59:59.660Z\n",
      "Inserting batch 14/34: batch_014.parquet\n",
      "rows: 3004567, Min Date: 2024-08-22T23:00:01.669Z, Max Date: 2024-09-01T23:00:00.202Z\n",
      "Inserting batch 15/34: batch_015.parquet\n",
      "rows: 3005184, Min Date: 2024-09-01T23:00:01.259Z, Max Date: 2024-09-11T23:00:00.696Z\n",
      "Inserting batch 16/34: batch_016.parquet\n",
      "rows: 2673293, Min Date: 2024-09-11T23:00:01.669Z, Max Date: 2024-09-21T23:00:00.841Z\n",
      "Inserting batch 17/34: batch_017.parquet\n",
      "rows: 2791481, Min Date: 2024-09-21T23:00:00.719Z, Max Date: 2024-10-01T22:59:59.014Z\n",
      "Inserting batch 18/34: batch_018.parquet\n",
      "rows: 2748438, Min Date: 2024-10-01T23:00:00.966Z, Max Date: 2024-10-17T22:59:59.756Z\n",
      "Inserting batch 19/34: batch_019.parquet\n",
      "rows: 3013772, Min Date: 2024-10-17T23:00:00.758Z, Max Date: 2024-10-28T00:00:02.547Z\n",
      "Inserting batch 20/34: batch_020.parquet\n",
      "rows: 3003581, Min Date: 2024-10-28T00:00:02.049Z, Max Date: 2024-11-07T00:00:01.026Z\n",
      "Inserting batch 21/34: batch_021.parquet\n",
      "rows: 2892316, Min Date: 2024-11-12T08:57:12.465Z, Max Date: 2024-11-22T00:00:00.739Z\n",
      "Inserting batch 22/34: batch_022.parquet\n",
      "rows: 3005730, Min Date: 2024-11-22T00:00:00.446Z, Max Date: 2024-12-01T23:59:58.461Z\n",
      "Inserting batch 23/34: batch_023.parquet\n",
      "rows: 2946755, Min Date: 2024-12-02T00:00:00.504Z, Max Date: 2024-12-12T00:00:00.507Z\n",
      "Inserting batch 24/34: batch_024.parquet\n",
      "rows: 2828046, Min Date: 2024-12-12T00:00:01.685Z, Max Date: 2025-01-21T23:59:59.697Z\n",
      "Inserting batch 25/34: batch_025.parquet\n",
      "rows: 2810412, Min Date: 2025-01-22T00:00:01.797Z, Max Date: 2025-01-31T23:59:59.034Z\n",
      "Inserting batch 26/34: batch_026.parquet\n",
      "rows: 3444748, Min Date: 2025-02-01T00:00:01.048Z, Max Date: 2025-02-11T00:00:00.247Z\n",
      "Inserting batch 27/34: batch_027.parquet\n",
      "rows: 3444792, Min Date: 2025-02-11T00:00:01.707Z, Max Date: 2025-02-21T00:00:02.579Z\n",
      "Inserting batch 28/34: batch_028.parquet\n",
      "rows: 3444896, Min Date: 2025-02-21T00:00:01.782Z, Max Date: 2025-03-03T00:00:00.439Z\n",
      "Inserting batch 29/34: batch_029.parquet\n",
      "rows: 3160644, Min Date: 2025-03-03T00:00:01.044Z, Max Date: 2025-03-19T23:59:58.314Z\n",
      "Inserting batch 30/34: batch_030.parquet\n",
      "rows: 2583156, Min Date: 2025-03-20T00:00:00.344Z, Max Date: 2025-03-29T23:59:59.883Z\n",
      "Inserting batch 31/34: batch_031.parquet\n",
      "rows: 2572740, Min Date: 2025-03-30T00:00:01.956Z, Max Date: 2025-04-08T23:00:02.067Z\n",
      "Inserting batch 32/34: batch_032.parquet\n",
      "rows: 2583606, Min Date: 2025-04-08T23:00:01.411Z, Max Date: 2025-04-18T23:00:00.912Z\n",
      "Inserting batch 33/34: batch_033.parquet\n",
      "rows: 2583780, Min Date: 2025-04-18T23:00:01.867Z, Max Date: 2025-04-28T23:00:00.850Z\n",
      "Inserting batch 34/34: batch_034.parquet\n",
      "rows: 258396, Min Date: 2025-04-28T23:00:00.237Z, Max Date: 2025-04-29T23:00:01.363Z\n"
     ]
    }
   ],
   "source": [
    "from tableauhyperapi import Inserter, Telemetry, CreateMode\n",
    "\n",
    "# Start Hyper process again to append data\n",
    "with HyperProcess(telemetry=\"DO_NOT_SEND_USAGE_DATA_TO_TABLEAU\") as hyper:\n",
    "    with Connection(endpoint=hyper.endpoint, database=output_hyper_file, create_mode=CreateMode.NONE) as connection:\n",
    "        \n",
    "        for idx, parquet_file in enumerate(all_parquet_files, start=1):\n",
    "            print(f\"Inserting batch {idx}/{len(all_parquet_files)}: {os.path.basename(parquet_file)}\")\n",
    "\n",
    "            # Read a single Parquet file into Polars\n",
    "            df = pl.read_parquet(parquet_file)\n",
    "\n",
    "            # Convert to list of tuples for insertion and confirm \n",
    "            rows = df.rows()\n",
    "            row_count = df.shape[0]\n",
    "            min_date = df[\"date\"].min()\n",
    "            max_date = df[\"date\"].max()\n",
    "            print(f\"rows: {row_count}, Min Date: {min_date}, Max Date: {max_date}\")\n",
    "\n",
    "            # Insert rows into Hyper file\n",
    "            with Inserter(connection, printer_table) as inserter:\n",
    "                inserter.add_rows(rows)\n",
    "                inserter.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55447a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date found: 2024-04-03T12:27:00.652Z in file: /Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float/batch_001.parquet\n",
      "Latest date found: 2025-04-29T23:00:01.363Z in file: /Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float/batch_034.parquet\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "\n",
    "all_files = sorted(glob.glob(\"/Users/tusharjoshi/Desktop/ProjectWorkAll/Dissertation /processed_float/*.parquet\"))\n",
    "\n",
    "first_date = None\n",
    "first_file = None\n",
    "\n",
    "\n",
    "latest_date = None\n",
    "latest_file = None\n",
    "\n",
    "for file in all_files:\n",
    "    df = pl.read_parquet(file)\n",
    "    max_date = df[\"date\"].max()\n",
    "    min_date = df[\"date\"].min()\n",
    "\n",
    "    if first_date is None or min_date < first_date:\n",
    "        first_date = min_date\n",
    "        first_file = file    \n",
    "\n",
    "\n",
    "    if latest_date is None or max_date > latest_date:\n",
    "\n",
    "        latest_date = max_date\n",
    "        latest_file = file\n",
    "\n",
    "\n",
    "print (f\"First date found: {first_date} in file: {first_file}\")\n",
    "print(f\"Latest date found: {latest_date} in file: {latest_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfcfe3",
   "metadata": {},
   "source": [
    "we have to check some issues with the hyper file when imported in tableau \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89085786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed tableauhyperapi version: 0.0.22502\n"
     ]
    }
   ],
   "source": [
    "import tableauhyperapi; print(f'Installed tableauhyperapi version: {tableauhyperapi.__version__}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Printer Env)",
   "language": "python",
   "name": "printer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
